拷贝文件/文件夹到远程，新老文件一并替换

```shell
aws s3 cp $localpath $s3Path
```

从远程同步文件/文件夹到本地，该命令只会同步修改或新添加的文件

```shell
aws s3 sync $s3Path $localPath --exclude "*" --include "*.txt" --dryrun
```

`--exclude "*"` 忽略所有文件<br>
`--include "*.txt"` 包含txt后缀文件<br>
`--dryrun` 则只对比差异，告诉你那些文件将被同步，无此参数，则会直接进行同步<br>
`--force` 可以强制覆盖<br>
`--verbose` 输出详细信息

是的，`aws s3 cp` 命令也支持使用 `--exclude` 和 `--include` 参数来指定排除或者特别包含的文件模式。

这些参数控制着具体哪些文件将被复制。使用 `--exclude` 参数可以排除匹配特定模式的文件，而 `--include` 参数则用来包含匹配特定模式的文件。在使用时，`--include` 和 `--exclude` 参数可以根据需要被多次使用来实现复杂的选择模式。

请记住，`aws s3 cp` 命令对单个文件或整个目录使用这些参数的效果有些不同。当您复制目录时，可以像 `aws s3 sync` 那样使用这些参数。

以下是一个使用 `--exclude` 和 `--include` 参数执行复制操作的例子，该命令拷贝一个 S3 存储桶的内容到其他位置，但只包括 `.txt` 扩展名的文件：

```shell
aws s3 cp s3://mybucket/ s3://myotherbucket/ --recursive --exclude "*" --include "*.txt"
```

在这个命令中：

- `--recursive` 参数表示复制整个目录。
- `--exclude "*"` 参数排除所有文件。
- `--include "*.txt"` 参数重新包含所有 `.txt` 文件。

重要的是知道，`aws s3 cp` 不会对目标进行增量检查。如果你没有指定 `--recursive`，即使源是一个目录/前缀，`cp` 命令也只复制单个文件。而且，如果目标 S3 路径已经存在相同的文件，`aws s3 cp` 命令将会覆盖它们，除非使用了其他参数如 `--no-clobber` 来防止覆盖。

要正确应用 `--include` 和 `--exclude` 过滤器，重要的是按照正确的顺序指定它们，因为这些过滤器将按照指定的顺序应用。通常，您应该先写 `--exclude` 规则，然后再写 `--include` 规则，因为最后一个匹配的规则决定一个文件是应该包含还是排除。


`aws s3 sync` 和 `aws s3 cp` 命令在 AWS CLI 中都是用来从一个 S3 存储桶拷贝文件到另一个存储桶或本地路径的，但是他们的用途和效果有一些不同。首先需要澄清，`aws s3 sync` 命令没有 `--force` 选项。

以下是两个命令的基本差异：

**aws s3 sync：**
- 用于将一个目录与另一个目录保持同步。
- 仅复制已更改的文件（基于文件的大小和最后修改时间）。
- 可以递归地复制目录。
- 支持 `--exclude` 和 `--include` 过滤器，用于精细控制哪些文件需要被同步。
- 默认不会复制存储桶中那些已经在目标端存在且没有发生改变的文件，以节省时间和带宽。

**aws s3 cp：**
- 用于复制文件或目录。
- 不会检查文件是否已改变，除非使用 `--only-show-errors` 选项去隐藏部分输出。
- 使用 `--recursive` 选项时可以像 `aws s3 sync` 那样复制目录，但它以简单复制为目的，不考虑同步的逻辑。
- 同样支持 `--exclude` 和 `--include` 过滤器，可以精细控制复制的文件。
- 如果不指定 `--recursive`，它默认只复制单个文件。
- 无论目标端文件是否存在或已更改，`cp` 总是执行复制操作。

简而言之，`aws s3 sync` 被设计为只更新那些自上次同步以来有变化的文件，而 `aws s3 cp` 更适用于简单的文件或目录复制任务。哪个命令更合适取决于你的特定需求，如果你需要执行完全的、精确的文件复制，不论文件是否已经在目标端存在或已更改，可以使用 `aws s3 cp`。而如果你希望保持一个目录和另一个目录间的增量同步，那么使用 `aws s3 sync` 更为合适。

如果在使用 `aws s3 sync` 时发现一些已更改的文件没有被同步，这可能是由以下几个原因造成的：

1. **时间戳与时区**: `aws s3 sync` 命令依赖源和目标文件的最后修改时间。如果源文件和目标文件的时间戳一样（或者在S3的时间分辨率范围内认为是相同的），即便内容有所不同，文件也不会被同步。另外，如果源和目标机器的时区设置不一致，这也可能影响文件的时间戳比较。

2. **S3 事件延迟**: S3 事件，如上传或更新文件，可能会有延迟。这可能导致 `aws s3 sync` 在某个时间点上还没有检测到文件的最新状态。

3. **权限问题**: 如果没有足够的权限来访问源或目标S3存储桶中的文件，这些文件将不会被同步。需要确保正确配置了 IAM 策略，给予了必要的 S3 权限。

4. **同步过滤器**: 如果使用了 `--exclude` 或 `--include` 参数，要确保这些过滤器没有意外地排除了应该同步的文件。`aws s3 sync` 会按照提供给它的排除和包含过滤器参数来处理文件。

5. **对象锁定**: 如果使用了 S3 版本控制和对象锁，可能存在被锁定版本的文件，阻止了更新。

6. **sync不比较文件内容**: `aws s3 sync` 并不比较源文件和目标文件的内容哈希值，它根据文件大小和最后修改时间来决定是否需要同步。如果文件在源端和目标端的大小相同且最后的修改时间没有超出检测阈值，即使内容不同，文件也不会被同步。

为了调试为何某些文件没有同步，您可以尝试以下操作：

- 使用 `--dryrun` 选项来运行 `aws s3 sync` 命令，这将展示哪些文件会被同步而不进行真正的同步操作。
- 使用 `--verbose` 选项可以获得更详细的执行输出。
- 检查权限和策略，确保您有权限访问并修改那些文件。
- 确认是否有其他 `--exclude` 或 `--include` 参数（记住，排除参数在包含参数之前处理）。

如果问题仍旧不解，可能需要更详细地检查 AWS CLI 的日志或联系 AWS 支持流程来获取帮助。
